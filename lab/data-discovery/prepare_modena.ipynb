{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d114a4-9d3d-445a-a5f0-a9fa2f07fe7c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba3622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 291200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036739f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/nanni/projects/bdm/lab/blend-duckdb/data/modena'), True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\".\", \"data\", \"modena\")\n",
    "original_tables_path = data_path.joinpath(\"tables\")\n",
    "data_lake_path = data_path.joinpath(\"data-lake\")\n",
    "queries_path = data_path.joinpath(\"queries\")\n",
    "milano_tables_path = data_path.joinpath(\"from_milan\")\n",
    "\n",
    "data_path.absolute(), data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1ea7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_lake_path.exists():\n",
    "    shutil.rmtree(data_lake_path)\n",
    "\n",
    "# (re-)create the data lake folder\n",
    "data_lake_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be56b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.remove('/home/nanni/projects/general-data-science/ULOD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d3d40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nanni/projects/general-data-science/correlation',\n",
       " '/home/nanni/projects/general-data-science/ULOD',\n",
       " '/home/nanni/projects/general-data-science/sloth',\n",
       " '/home/nanni/projects/general-data-science/JOSIE',\n",
       " '/home/nanni/projects/general-data-science/BLEND',\n",
       " '/home/nanni/mystuff/py_datafusion/src',\n",
       " '/home/nanni/projects/bdm/lab/blend-duckdb',\n",
       " '/home/nanni/miniconda3/lib/python313.zip',\n",
       " '/home/nanni/miniconda3/lib/python3.13',\n",
       " '/home/nanni/miniconda3/lib/python3.13/lib-dynload',\n",
       " '',\n",
       " '/home/nanni/projects/bdm/lab/blend-duckdb/.venv/lib/python3.13/site-packages',\n",
       " '/home/nanni/projects/bdm/lab/modules/ULOD']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules_path = Path(\"..\", \"modules\", \"ULOD\")\n",
    "\n",
    "sys.path.append(str(modules_path.resolve()))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402b3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ulod.ckan import ModenaCKAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49803ff1",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e538d1e",
   "metadata": {},
   "source": [
    "For this lab we will use some datasets from Modena (and Milan) Open Data. Before using them for the lab, however, we need to preprocess them, to create\n",
    "a \"data-lake\"-like context.\n",
    "\n",
    "We want to normalize all the cell values before the ingestion, in order to make data discovery and post-processing easier\n",
    "\n",
    "First, we observe that the district names are heterogeneous among datasets; we can normalize them with a simple function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f1ff9",
   "metadata": {},
   "source": [
    "### Normalize district names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82952812",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import difflib\n",
    "\n",
    "# official districts\n",
    "DISTRICTS = [\"Crocetta\", \"San Faustino\", \"Centro\", \"Buon Pastore\"]\n",
    "\n",
    "def normalize_district(district: str) -> str:\n",
    "    district_lw = district.lower()\n",
    "\n",
    "    # split the lowercase district name in some parts, given possible separators\n",
    "    splits = [p.strip() for p in re.split(r\"[-/,]\", district_lw) if p.strip()]\n",
    "\n",
    "    migliori = []\n",
    "    for split in splits:\n",
    "        # identify the name that is closer to the target (if any)\n",
    "        match = difflib.get_close_matches(split, [q.lower() for q in DISTRICTS], n=1, cutoff=0.5)\n",
    "        if match:\n",
    "            # map to the canonical form\n",
    "            idx = [q.lower() for q in DISTRICTS].index(match[0])\n",
    "            migliori.append(DISTRICTS[idx])\n",
    "\n",
    "    # if many candidates are identified, returns only the first one\n",
    "    if migliori:\n",
    "        return list(dict.fromkeys(migliori))[0] \n",
    "    \n",
    "    # otherwise, return the original one\n",
    "    return district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c871d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.Lazzaro ->  S.Lazzaro\n",
      "B.Pastore ->  Buon Pastore\n",
      "BUON PASTORE-S.AGNESE-S.DAMASO ->  Buon Pastore\n",
      "Centro storico ->  Centro\n",
      "S.FAUSTINO-MADONNINA ->  San Faustino\n"
     ]
    }
   ],
   "source": [
    "print(\"S.Lazzaro -> \", normalize_district(\"S.Lazzaro\"))\n",
    "print(\"B.Pastore -> \", normalize_district(\"B.Pastore\"))\n",
    "print(\"BUON PASTORE-S.AGNESE-S.DAMASO -> \", normalize_district(\"BUON PASTORE-S.AGNESE-S.DAMASO\"))\n",
    "print(\"Centro storico -> \", normalize_district(\"Centro storico\"))\n",
    "print('S.FAUSTINO-MADONNINA -> ', normalize_district('S.FAUSTINO-MADONNINA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d70935",
   "metadata": {},
   "source": [
    "## Clean and Merge Milan Open Data tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ad62c",
   "metadata": {},
   "source": [
    "We add some datasets from Milan Open Data. \n",
    "We need to:\n",
    "- clean the float values;\n",
    "- clean the column names;\n",
    "- clean the dataset names;\n",
    "- map Milan districts to Modena districts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26a0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_float(s: str):\n",
    "    cnt = s.count(',')\n",
    "    match cnt:\n",
    "        case 0: # if no comma, return the string\n",
    "            return s\n",
    "        case 1: \n",
    "            # if one comma, replace it with a dot, if\n",
    "            # not in the string yet\n",
    "            if '.' not in s:\n",
    "                return s.replace(',', '.')\n",
    "            else:\n",
    "                return s.replace(',', '')\n",
    "        case 2:\n",
    "            # with more than one comma, replace the first\n",
    "            return s.replace(',', '', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7208a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1929', '19.29', '190.2', '1999,333.293')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_float('1929'), clean_float('19,29'), clean_float('1,90.2'), clean_float(\"1,999,333.293\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61a93a",
   "metadata": {},
   "source": [
    "Here we cast string values to float, and next rename the datasets column names to english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "706ada29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in os.listdir(milano_tables_path):\n",
    "    df = pl.read_csv(milano_tables_path.joinpath(table), separator=';', encoding='utf8-lossy')\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.col('Spesa media mensile familiare (in euro)')\n",
    "        .map_elements(clean_float, pl.String)\n",
    "        .cast(pl.Float32)\n",
    "        .alias('Spesa media mensile familiare (in euro)')\n",
    "    )\n",
    "\n",
    "    df = df.rename(\n",
    "        {\n",
    "            'Anno': 'YEAR',\n",
    "            'Anello territoriale': 'DISTRICT',\n",
    "            'Tipologia di beni': 'TYPE',\n",
    "            'Categoria': 'CATEGORY',\n",
    "            'Spesa media mensile familiare (in euro)': 'AVG MONTH FAMILIAR EXPENSE (€)',\n",
    "            'Reddito del nucleo familiare': 'HOUSEHOLD INCOME',\n",
    "            'Numero di figli': 'NUMBER OF CHILDREN',\n",
    "            'Numero componenti del nucleo familiare': 'NUMBER OF FAMILY MEMBERS'\n",
    "        },\n",
    "        strict=False\n",
    "    )\n",
    "\n",
    "    df.write_csv(original_tables_path.joinpath(table), separator=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e7acd",
   "metadata": {},
   "source": [
    "Then, we map Milan to Modena district names, and add a slight random change to the avg month familiar expense column\n",
    "(just for testing later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269e5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_district(s: str):\n",
    "    match s:\n",
    "        case 'Centro': return 'Centro'\n",
    "        case 'Semicentro': return 'Crocetta'\n",
    "        case 'Periferia': return 'San Faustino'\n",
    "        case _: return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6555a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "for table in os.listdir(milano_tables_path):\n",
    "    df = pl.read_csv(milano_tables_path.joinpath(table), separator=\";\", encoding=\"latin-1\")\n",
    "\n",
    "    df = df.rename(\n",
    "        {\n",
    "            \"Anno\": \"YEAR\",\n",
    "            \"Categoria\": \"CATEGORY\",\n",
    "            \"Tipologia di beni\": \"TYPE\",\n",
    "            \"Anello territoriale\": \"DISTRICT\", \n",
    "            \"Numero di figli\": \"NUMBER OF CHILDREN\",\n",
    "            \"Numero componenti del nucleo familiare\": \"NUMBER OF FAMILY MEMBERS\",\n",
    "            \"Reddito del nucleo familiare\": \"HOUSEHOLD INCOME\",\n",
    "            \"Spesa media mensile familiare (in euro)\": \"AVG MONTH FAMILIAR EXPENSE (€)\"\n",
    "        }, strict=False\n",
    "    ).with_columns(\n",
    "        # cast the expense column to float\n",
    "        pl.col(\"AVG MONTH FAMILIAR EXPENSE (€)\").map_elements(clean_float, pl.String).cast(pl.Float64)\n",
    "    )\n",
    "\n",
    "    if \"DISTRICT\" in df.columns:\n",
    "        # add a section to the dataset wit the same number of records of that \n",
    "        # from \"Periferia\", and change the expense\n",
    "        sub = df.filter(pl.col('DISTRICT') == 'Periferia') \\\n",
    "            .with_columns(\n",
    "                pl.lit('Buon Pastore').alias('DISTRICT'),\n",
    "                pl.col('AVG MONTH FAMILIAR EXPENSE (€)') + pl.col('AVG MONTH FAMILIAR EXPENSE (€)') * random.random()\n",
    "            )\n",
    "        \n",
    "        df = pl.concat([df, sub]).with_columns(pl.col('DISTRICT').map_elements(rename_district, pl.String))\n",
    "        \n",
    "    epsilon_per_year = {\n",
    "        2014: 0.01,\n",
    "        2015: 0.01,\n",
    "        2016: 0.02,\n",
    "        2017: 0.01,\n",
    "        2018: 0.02,\n",
    "        2019: 0.01,\n",
    "        2020: 0.1,\n",
    "        2021: 0.12,\n",
    "        2022: 0.06,\n",
    "        2023: 0.02\n",
    "    }\n",
    "\n",
    "    for year, epsilon in epsilon_per_year.items():\n",
    "        last = df.filter(pl.col('YEAR') == pl.col('YEAR').max())\n",
    "        e = pl.Series(values=[epsilon + np.random.uniform(-0.015, 0.03) for _ in range(last.shape[0])])\n",
    "\n",
    "        new = last.with_columns(\n",
    "            pl.lit(year).cast(pl.Int64).alias('YEAR'),\n",
    "            (pl.col('AVG MONTH FAMILIAR EXPENSE (€)') + pl.col('AVG MONTH FAMILIAR EXPENSE (€)') * e).round(2).alias('AVG MONTH FAMILIAR EXPENSE (€)')\n",
    "        )\n",
    "\n",
    "        df = pl.concat([df, new])\n",
    "        df.write_csv(original_tables_path.joinpath(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a651b",
   "metadata": {},
   "source": [
    "## Create the data-lake datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6491a",
   "metadata": {},
   "source": [
    "From previous step, we have partially prepared the datasets. \n",
    "To add some noise, like duplicate tables, with partial overlaps, potential joins, etc., we can create these situations.\n",
    "\n",
    "Also, there are many datasets about local elections: we can add useful columns about them, like the election type and the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b7f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fake_useragent\n",
    "\n",
    "ua = fake_useragent.UserAgent()\n",
    "client = ModenaCKAN(headers={\"User-Agent\": ua.firefox})\n",
    "\n",
    "def refine_name(name: str):\n",
    "    _, rsc_id = name.removesuffix('.csv').split('::')\n",
    "    \n",
    "    result = client.resource_show(id=rsc_id)\n",
    "\n",
    "    pkg_id = result['result']['package_id']\n",
    "\n",
    "    result = client.package_show(id=pkg_id)\n",
    "    if len([r for r in result['result']['resources'] if r['format'].upper() == 'CSV']) != 1:\n",
    "        print(f'Problem: {name}, {pkg_id}, {len(result['result']['resources'])}')\n",
    "        return name\n",
    "    \n",
    "    title = result['result']['title']\n",
    "\n",
    "    title = '-'.join(title.split())\n",
    "    title = f'{title}::{rsc_id}.csv'\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d823e06b-f43f-4de0-b2f3-d46bef24cff7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "# remove the data-lake folder and re-create it\n",
    "shutil.rmtree(data_lake_path)\n",
    "data_lake_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for table in os.listdir(original_tables_path): \n",
    "    original_table = table\n",
    "    if not table.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    if any(x in table.lower() for x in {'senato', 'camera', 'sindaco', 'dei-candidati'}):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = pl.read_csv(original_tables_path.joinpath(table), infer_schema_length=10_000, truncate_ragged_lines=True)\n",
    "        # print('ELEZIONE' in df.columns, table)\n",
    "        if 'ELEZIONE' in df.columns:            \n",
    "            df = df.with_columns(\n",
    "                ELEZIONE=pl.col('ELEZIONE').str.split(' ').list.filter(pl.element().str.starts_with('20').not_()).list.join(' ').str.strip_chars(), \n",
    "                ANNO=pl.col('ELEZIONE').str.split(' ').list.filter(pl.element().str.starts_with('20')).list.join(' ').cast(pl.Int64)\n",
    "            )\n",
    "\n",
    "            # add the circoscrizione, and relative code, columns\n",
    "            df = df.with_columns(\n",
    "                CIRCOSCRIZIONE_CD=pl.col('CIRCOSCRIZIONE').str.extract(r\"(\\d?)\", 0).cast(pl.Int64),\n",
    "                CIRCOSCRIZIONE=pl.col('CIRCOSCRIZIONE').str.extract(r\"([A-Za-z\\. ]+)\", 1)\n",
    "            )\n",
    "\n",
    "            df = df.drop('CIRCOSCRIZIONE_CD').insert_column(df.get_column_index('CIRCOSCRIZIONE') + 1, df.get_column('CIRCOSCRIZIONE_CD'))\n",
    "            \n",
    "            # place the year column next to the election type column\n",
    "            df = df.drop('ANNO').insert_column(df.get_column_index('ELEZIONE') + 1, df.get_column('ANNO'))\n",
    "\n",
    "            # clean some column names about political parties\n",
    "            for column in df.columns:\n",
    "                try:\n",
    "                    if 'LEGA_' in column:\n",
    "                        df = df.rename({column: 'LEGA'})\n",
    "                    elif 'FORZA_ITALIA' in column:\n",
    "                        df = df.rename({column: 'FORZA_ITALIA'})\n",
    "                    elif 'FDI' in column or 'FRATELLI_D' in column or 'GIORGIA_MELONI' in column:\n",
    "                        df = df.rename({column: 'FRATELLI_D_ITALIA'})\n",
    "                    elif 'BONACCINI' in column: \n",
    "                        df = df.rename({column: \"STEFANO BONACCINI\"})\n",
    "                    elif 'MOVIMENTO' in column and ('BEPPE' in column or '5' in column or 'STELLE' in column):\n",
    "                        df = df.rename({column: 'MOVIMENTO_5_STELLE'})\n",
    "                except Exception as e:\n",
    "                    print(df.columns)\n",
    "                    raise e\n",
    "                \n",
    "        # normalize district/quarter names\n",
    "        for c in ['CIRCOSCRIZIONE', 'QUARTIERE', 'QUA_DES_D', 'QUA_DES_P']:\n",
    "            if c in df.columns and not df.get_column(c).dtype.is_numeric():\n",
    "                df = df.with_columns(\n",
    "                    pl.col(c).map_elements(normalize_district, pl.String).alias(c)\n",
    "                )\n",
    "        \n",
    "        # select columns that to drop\n",
    "        to_drop = ['FID', 'SHAPE', 'NOMEFILE', 'OBJECTID', 'ID_CIRCOSCRIZIONE', 'NOME_CIRCOSCRIZIONE', 'the_geom']\n",
    "        if ('SEZIONE' in df.columns and 'SEZ_ELETT' in df.columns) or ('SEZ' in df.columns and 'SEZ_ELETT' in df.columns):\n",
    "            to_drop.append('SEZ_ELETT')\n",
    "        df = df.drop(to_drop, strict=False)\n",
    "\n",
    "        # at this time, this part is not used\n",
    "        if 'Risultati' in table:\n",
    "            base_headers = [\n",
    "                'SEZIONE', 'SEZ_ELETT', 'SEZ', \n",
    "                'CIRCOSCRIZIONE', 'CIRCOSCRIZIONE_CD', \n",
    "                'ID_CIRCOSCRIZIONE', 'NOME_CIRCOSCRIZIONE',\n",
    "                'TIPODATI', 'TIPO_DATI', \n",
    "                'ELEZIONE', 'ANNO', 'SCHEDA', 'ISCRITTI']\n",
    "            partiti_candidati = [x for x in df.columns if x not in base_headers and 'TOTALE' not in x]\n",
    "\n",
    "        # remove this prefix to make the dataset name consistent with other cases\n",
    "        table = table.removeprefix('Accesso-al-dataset-')\n",
    "\n",
    "        # some datasets have unclear names: we can get from the Open Data portal\n",
    "        # a better versior of it \n",
    "        if 'Risorsa-in-formato' in table:\n",
    "            table = refine_name(table)\n",
    "\n",
    "        table = table.split('::')[0].removesuffix(\".csv\") + \".csv\"\n",
    "\n",
    "        # finally, rename the column names to english\n",
    "        df = df.rename(\n",
    "            {\n",
    "                'SEZIONE': 'SECTION',\n",
    "                'SEZ_ELETT': 'SECTION', \n",
    "                'SEZ': 'SECTION', \n",
    "                'CIRCOSCRIZIONE': 'DISTRICT',\n",
    "                'CIRCOSCRIZIONE_CD': 'DISTRICT_CD',\n",
    "                'TIPODATI': 'DATA_TYPE',\n",
    "                'TIPO_DATI': 'DATA_TYPE',\n",
    "                'ANNO': 'YEAR',\n",
    "                'ELEZIONE': 'ELECTION',\n",
    "                'COD_ELEZIONE': 'ELECTION_CD',\n",
    "                'SCHEDA': 'FORM',\n",
    "                'TOTALE_VOTANTI': '#VOTERS',\n",
    "                'TOTALE_SCHEDE_BIANCHE': '#BLANK',\n",
    "                'TOTALE_VOTI_VALIDI': '#VALID',\n",
    "                'ISCRITTI': '#REGISTERED',\n",
    "                'ISCRITTI_MASCHI': '#MALE_REGISTERED',\n",
    "                'ISCRITTI_FEMMINE': '#FEMALE_REGISTERED',\n",
    "                'VOTANTI_MASCHI': '#MALE_VOTERS',\n",
    "                'VOTANTI_FEMMINE': '#FEMALE_VOTERS',\n",
    "                'TOTALE_SCHEDE_CONTESTATE': '#DISPUTED',\n",
    "                'TOTALE_VOTI_DI_CUI': '#OF WHICH',\n",
    "                'TOTALE_VOTI_NON_VALIDI': '#NOT VALID',\n",
    "                'TOTALE_SCHEDE_NULLE': '#NULL'\n",
    "                \n",
    "            }, strict=False\n",
    "        )\n",
    "\n",
    "        df.write_csv(data_lake_path.joinpath(table))\n",
    "    except Exception as e:\n",
    "        print(f\"\\nerror: {e}, table: {original_table}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8d78a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_years = defaultdict(list)\n",
    "\n",
    "# make aggregated table over multiple years\n",
    "for table in os.listdir(data_lake_path):\n",
    "    df = pl.read_csv(data_lake_path.joinpath(table), infer_schema_length=10_000, truncate_ragged_lines=True)\n",
    "    try:\n",
    "        if 'ELEZIONE' in df.columns and 'generale' not in table:            \n",
    "            year = re.search(r\"(\\d+)\", table).group(0)\n",
    "            base_str = table.replace('.csv', '').replace(year, '')\n",
    "            multi_years[base_str].append(year)\n",
    "\n",
    "            for base_str, years in multi_years.items():\n",
    "                if len(years) == 1:\n",
    "                    continue\n",
    "                formatted = re.sub(r\"(del|delle)-$\", \"\", base_str) + 'generale.csv'\n",
    "                dfs = [pl.scan_csv(data_lake_path.joinpath(f\"{base_str}{year}.csv\")) for year in sorted(years)]\n",
    "                general = pl.concat(dfs, how='diagonal_relaxed').collect()\n",
    "                general.write_csv(data_lake_path.joinpath(formatted))\n",
    "    except Exception as e:\n",
    "        print(e, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eac3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake single-column-unique-key\n",
    "for table in os.listdir(data_lake_path.joinpath()):\n",
    "    df = pl.read_csv(data_lake_path.joinpath(table), infer_schema_length=10_000, truncate_ragged_lines=True)\n",
    "    \n",
    "    if 'ELECTION' in df.columns:\n",
    "        df = df.drop('THE_PK_KEY', strict=False).with_columns(\n",
    "            THE_PK_KEY=pl.concat_str(['SECTION', 'DISTRICT', 'ELECTION'], separator='_').str.strip_chars()\n",
    "        )\n",
    "\n",
    "        assert df.get_column('THE_PK_KEY').is_unique().all()\n",
    "\n",
    "        df = df.drop('THE_PK_KEY').insert_column(0, df.get_column('THE_PK_KEY'))\n",
    "        \n",
    "        df.write_csv(data_lake_path.joinpath(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc6f45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make unpivoted tables based on party names\n",
    "for table in os.listdir(data_lake_path):\n",
    "    if 'unpivot' in table:\n",
    "        os.remove(data_lake_path.joinpath(table))\n",
    "\n",
    "\n",
    "for table in os.listdir(data_lake_path):\n",
    "    df = pl.read_csv(data_lake_path.joinpath(table), infer_schema_length=10_000, truncate_ragged_lines=True).drop('THE_PK_KEY', strict=False)\n",
    "    try:\n",
    "        if 'ELECTION' in df.columns and 'Risultati' in table:\n",
    "            base_headers = ['SECTION', 'DISTRICT', 'DATA_TYPE', 'ELECTION', 'YEAR', 'FORM']\n",
    "\n",
    "            on = [x for x in df.columns if x not in base_headers and '#' not in x]\n",
    "\n",
    "            u_df = df.unpivot(on, index=base_headers).rename({'variable': 'CANDIDATE/PARTY', 'value': 'VOTES'})\n",
    "\n",
    "            u_df = u_df.with_columns(VOTES=pl.col('VOTES').cast(pl.Int64))\n",
    "            unpivot_name = table.removesuffix('.csv') + '.unpivot.csv'\n",
    "\n",
    "            u_df.write_csv(data_lake_path.joinpath(unpivot_name))\n",
    "    except Exception as e:\n",
    "        print(table, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da9e83",
   "metadata": {},
   "source": [
    "### Create random copies with modified overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fc661",
   "metadata": {},
   "source": [
    "We then add to the datalake some random copies with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabee3f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2024.csv - 529\n",
      "Created 1 copy of Risultati-delle-elezioni-europee-2019.unpivot.csv - 1223\n",
      "Created 2 copy of Risultati-delle-elezioni-europee-2019.unpivot.csv - 1078\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2009.unpivot.csv - 1027\n",
      "Created 2 copy of Affluenze-delle-elezioni-regionali-2014.csv - 98\n",
      "Created 1 copy of Affluenze-e-risultati-elettorali-delle-elezioni-amministrative-2024.csv - 84\n",
      "Created 2 copy of Affluenze-e-risultati-elettorali-delle-elezioni-amministrative-2024.csv - 90\n",
      "Created 1 copy of Affluenzedelle-elezioni-regionali-2020.csv - 98\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-regionali-del-2014.csv - 349\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-regionali-del-2014.csv - 383\n",
      "Created 1 copy of Risultati-delle-elezioni-europee-anno-2014.csv - 492\n",
      "Created 2 copy of Risultati-delle-elezioni-europee-anno-2014.csv - 473\n",
      "Created 1 copy of Affluenze-delle-elezioni-regionali-2010.csv - 95\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-regionali-del-2024.unpivot.csv - 781\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2009.csv - 546\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-europee-del-2024.unpivot.csv - 787\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2014.unpivot.csv - 964\n",
      "Created 1 copy of Affluenze-e-risultati-elettorali-delle-elezioni-regionali-2024.csv - 97\n",
      "Created 2 copy of Affluenze-e-risultati-elettorali-delle-elezioni-regionali-2024.csv - 99\n",
      "Created 1 copy of Risultati-delle-elezioni-europee-anno-2014.unpivot.csv - 927\n",
      "Created 2 copy of Risultati-delle-elezioni-europee-anno-2014.unpivot.csv - 853\n",
      "Created 2 copy of Risultati-delle-elezioni-europee-2009.unpivot.csv - 889\n",
      "Created 1 copy of Affluenze-delle-elezioni-europee-2019.csv - 90\n",
      "Created 2 copy of Affluenze-delle-elezioni-europee-2019.csv - 102\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-regionali-del-2020.unpivot.csv - 1148\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-regionali-del-2020.unpivot.csv - 1132\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-regionali-del-2024.csv - 397\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-regionali-del-2024.csv - 391\n",
      "Created 2 copy of Affluenze-al-ballottaggio-delle-elezioni-amministrative-2014.csv - 96\n",
      "Created 1 copy of Affluenze-delle-elezioni-amministrative-2014.csv - 83\n",
      "Created 1 copy of Risultati-delle-elezioni-europee-2009.csv - 483\n",
      "Created 2 copy of Risultati-delle-elezioni-europee-2009.csv - 486\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-regionali-del-2020.csv - 727\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-europee-del-2024.csv - 423\n",
      "Created 1 copy of Affluenze-e-risultati-elettorali-delle-elezioni-europee-2024.csv - 83\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2019.csv - 645\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-regionali-del-2014.unpivot.csv - 681\n",
      "Created 1 copy of Affluenze-delle-elezioni-amministrative-2009.csv - 78\n",
      "Created 2 copy of Affluenze-delle-elezioni-amministrative-2009.csv - 93\n",
      "Created 1 copy of Risultati-delle-elezioni-europee-2019.csv - 692\n",
      "Created 2 copy of Risultati-delle-elezioni-europee-2019.csv - 732\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-regionali-del-2010.csv - 419\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2024.unpivot.csv - 1030\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2014.csv - 548\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-amministrative-del-2014.csv - 534\n",
      "Created 1 copy of Risultati-di-lista-delle-elezioni-regionali-del-2010.unpivot.csv - 593\n",
      "Created 2 copy of Risultati-di-lista-delle-elezioni-regionali-del-2010.unpivot.csv - 560\n",
      "Created 1 copy of Affluenze-delle-elezioni-amministrative-2019.csv - 92\n",
      "Created 2 copy of Affluenze-delle-elezioni-amministrative-2019.csv - 98\n"
     ]
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "\n",
    "for table in os.listdir(data_lake_path):\n",
    "    if 'cpy' in table:\n",
    "        os.remove(data_lake_path.joinpath(table))\n",
    "\n",
    "distinct_names = set()\n",
    "\n",
    "base_headers = ['SECTION', 'DISTRICT', 'DISTRICT', 'DATA_TYPE', 'ELECTION', 'YEAR', 'FORM']\n",
    "\n",
    "number_of_copies = 2\n",
    "\n",
    "for table in os.listdir(data_lake_path):\n",
    "    df = pl.read_csv(data_lake_path.joinpath(table), infer_schema_length=10_000, truncate_ragged_lines=True)\n",
    "    if 'ELECTION' in df.columns:\n",
    "        for cpy_number in range(number_of_copies):\n",
    "            # first random: the table will be duplicated?\n",
    "            if (create_copy := random.random()) < 0.6:\n",
    "                cpy_name = table.removesuffix('.csv') + f'.cpy-{cpy_number}.csv'\n",
    "\n",
    "                # second random: sampling rows\n",
    "                cpy = df.with_row_index().sample(fraction=max(0.8, random.random()), shuffle=False, seed=SEED).sort('index').drop('index')\n",
    "\n",
    "                for column in df.columns:\n",
    "                    if column not in base_headers and '#' not in column:\n",
    "                        # for numerical columns only, put random Null values inside them\n",
    "                        cpy = cpy.with_columns(\n",
    "                            pl.col(column).map_elements(\n",
    "                                # third random: place null values instead of original ones\n",
    "                                lambda e: None if random.random() < 0.2 else e, \n",
    "                                df.get_column(column).dtype\n",
    "                            ).alias(column)\n",
    "                        )\n",
    "                        \n",
    "                cpy.write_csv(data_lake_path.joinpath(cpy_name))\n",
    "                null_cnt = cpy.null_count().sum_horizontal()\n",
    "                print(f\"Created {cpy_number + 1} copy of {table} - {null_cnt[0]}\")\n",
    "\n",
    "        if 'Affluenze' not in table:\n",
    "            distinct_names.update([x for x in df.columns if x not in base_headers and '#' not in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f45b189-1292-4c0c-bbc3-987b3474631b",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 33)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>THE_PK_KEY</th><th>SECTION</th><th>DISTRICT</th><th>DISTRICT_CD</th><th>DATA_TYPE</th><th>ELECTION</th><th>YEAR</th><th>EUROPA_VERDE</th><th>LEGA</th><th>FRATELLI_D_ITALIA</th><th>PARTITO_PIRATA</th><th>IL_POPOLO_DELLA_FAMIGLIA</th><th>PARTITO_ANIMALISTA</th><th>PARTITO_DEMOCRATICO</th><th>LA_SINISTRA</th><th>PPA_POPOLO_PARTITE_IVA</th><th>PI__EUROPA</th><th>MOVIMENTO_5_STELLE</th><th>POPOLARI_PER_L_ITALIA</th><th>FORZA_NUOVA</th><th>FORZA_ITALIA</th><th>SVP</th><th>PARTITO_COMUNISTA</th><th>CASAPOUND___DESTRE_UNITE</th><th>FORM</th><th>#VOTERS</th><th>#BLANK</th><th>#VALID</th><th>#REGISTERED</th><th>#DISPUTED</th><th>#OF WHICH</th><th>#NOT VALID</th><th>#NULL</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1_Centro_Europee&quot;</td><td>1</td><td>&quot;Centro&quot;</td><td>1</td><td>&quot;Liste&quot;</td><td>&quot;Europee&quot;</td><td>2019</td><td>21</td><td>181</td><td>39</td><td>0</td><td>4</td><td>3</td><td>197</td><td>14</td><td>0</td><td>32</td><td>46</td><td>0</td><td>0</td><td>59</td><td>0</td><td>3</td><td>0</td><td>&quot;E19&quot;</td><td>606</td><td>0</td><td>599</td><td>847</td><td>1</td><td>null</td><td>7</td><td>6</td></tr><tr><td>&quot;2_Centro_Europee&quot;</td><td>2</td><td>&quot;Centro&quot;</td><td>1</td><td>&quot;Liste&quot;</td><td>&quot;Europee&quot;</td><td>2019</td><td>19</td><td>123</td><td>22</td><td>1</td><td>3</td><td>0</td><td>155</td><td>10</td><td>0</td><td>29</td><td>34</td><td>0</td><td>0</td><td>46</td><td>0</td><td>5</td><td>2</td><td>&quot;E19&quot;</td><td>461</td><td>3</td><td>449</td><td>704</td><td>0</td><td>null</td><td>12</td><td>9</td></tr><tr><td>&quot;3_Centro_Europee&quot;</td><td>3</td><td>&quot;Centro&quot;</td><td>1</td><td>&quot;Liste&quot;</td><td>&quot;Europee&quot;</td><td>2019</td><td>26</td><td>167</td><td>57</td><td>1</td><td>0</td><td>3</td><td>170</td><td>11</td><td>0</td><td>36</td><td>38</td><td>2</td><td>0</td><td>72</td><td>1</td><td>6</td><td>1</td><td>&quot;E19&quot;</td><td>601</td><td>5</td><td>591</td><td>826</td><td>0</td><td>null</td><td>10</td><td>5</td></tr><tr><td>&quot;4_Centro_Europee&quot;</td><td>4</td><td>&quot;Centro&quot;</td><td>1</td><td>&quot;Liste&quot;</td><td>&quot;Europee&quot;</td><td>2019</td><td>27</td><td>144</td><td>57</td><td>1</td><td>3</td><td>0</td><td>184</td><td>17</td><td>1</td><td>35</td><td>46</td><td>0</td><td>0</td><td>56</td><td>0</td><td>4</td><td>0</td><td>&quot;E19&quot;</td><td>587</td><td>6</td><td>575</td><td>841</td><td>0</td><td>null</td><td>12</td><td>6</td></tr><tr><td>&quot;5_Centro_Europee&quot;</td><td>5</td><td>&quot;Centro&quot;</td><td>1</td><td>&quot;Liste&quot;</td><td>&quot;Europee&quot;</td><td>2019</td><td>19</td><td>147</td><td>48</td><td>2</td><td>0</td><td>6</td><td>179</td><td>12</td><td>1</td><td>28</td><td>37</td><td>1</td><td>0</td><td>58</td><td>0</td><td>0</td><td>3</td><td>&quot;E19&quot;</td><td>560</td><td>14</td><td>541</td><td>818</td><td>0</td><td>null</td><td>19</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 33)\n",
       "┌──────────────┬─────────┬──────────┬─────────────┬───┬───────────┬───────────┬────────────┬───────┐\n",
       "│ THE_PK_KEY   ┆ SECTION ┆ DISTRICT ┆ DISTRICT_CD ┆ … ┆ #DISPUTED ┆ #OF WHICH ┆ #NOT VALID ┆ #NULL │\n",
       "│ ---          ┆ ---     ┆ ---      ┆ ---         ┆   ┆ ---       ┆ ---       ┆ ---        ┆ ---   │\n",
       "│ str          ┆ i64     ┆ str      ┆ i64         ┆   ┆ i64       ┆ str       ┆ i64        ┆ i64   │\n",
       "╞══════════════╪═════════╪══════════╪═════════════╪═══╪═══════════╪═══════════╪════════════╪═══════╡\n",
       "│ 1_Centro_Eur ┆ 1       ┆ Centro   ┆ 1           ┆ … ┆ 1         ┆ null      ┆ 7          ┆ 6     │\n",
       "│ opee         ┆         ┆          ┆             ┆   ┆           ┆           ┆            ┆       │\n",
       "│ 2_Centro_Eur ┆ 2       ┆ Centro   ┆ 1           ┆ … ┆ 0         ┆ null      ┆ 12         ┆ 9     │\n",
       "│ opee         ┆         ┆          ┆             ┆   ┆           ┆           ┆            ┆       │\n",
       "│ 3_Centro_Eur ┆ 3       ┆ Centro   ┆ 1           ┆ … ┆ 0         ┆ null      ┆ 10         ┆ 5     │\n",
       "│ opee         ┆         ┆          ┆             ┆   ┆           ┆           ┆            ┆       │\n",
       "│ 4_Centro_Eur ┆ 4       ┆ Centro   ┆ 1           ┆ … ┆ 0         ┆ null      ┆ 12         ┆ 6     │\n",
       "│ opee         ┆         ┆          ┆             ┆   ┆           ┆           ┆            ┆       │\n",
       "│ 5_Centro_Eur ┆ 5       ┆ Centro   ┆ 1           ┆ … ┆ 0         ┆ null      ┆ 19         ┆ 5     │\n",
       "│ opee         ┆         ┆          ┆             ┆   ┆           ┆           ┆            ┆       │\n",
       "└──────────────┴─────────┴──────────┴─────────────┴───┴───────────┴───────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv(data_lake_path.joinpath('Risultati-delle-elezioni-europee-2019.csv'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66d97030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (190, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SECTION</th><th>DISTRICT_CD</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>2</td><td>1</td></tr><tr><td>3</td><td>1</td></tr><tr><td>4</td><td>1</td></tr><tr><td>5</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>186</td><td>4</td></tr><tr><td>187</td><td>3</td></tr><tr><td>188</td><td>3</td></tr><tr><td>189</td><td>3</td></tr><tr><td>190</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (190, 2)\n",
       "┌─────────┬─────────────┐\n",
       "│ SECTION ┆ DISTRICT_CD │\n",
       "│ ---     ┆ ---         │\n",
       "│ i64     ┆ i64         │\n",
       "╞═════════╪═════════════╡\n",
       "│ 1       ┆ 1           │\n",
       "│ 2       ┆ 1           │\n",
       "│ 3       ┆ 1           │\n",
       "│ 4       ┆ 1           │\n",
       "│ 5       ┆ 1           │\n",
       "│ …       ┆ …           │\n",
       "│ 186     ┆ 4           │\n",
       "│ 187     ┆ 3           │\n",
       "│ 188     ┆ 3           │\n",
       "│ 189     ┆ 3           │\n",
       "│ 190     ┆ 4           │\n",
       "└─────────┴─────────────┘"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save a particulare dataset just for testing\n",
    "codes_only = df.select(\"SECTION\", \"DISTRICT_CD\")\n",
    "codes_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a42c60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_only.write_csv(queries_path.joinpath(\"section_district_codes.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
